# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j9RjBpWwc07sdy8wZUidck1gvKwEx0ie
"""

from bs4 import BeautifulSoup as soup
from urllib.request import urlopen, Request
import pandas as pd

def scrape_website(url, class_name):
    all_teams = []
    request = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    uClient = urlopen(request)
    page_soup = soup(uClient.read(), "html.parser")
    uClient.close()
    ul_tag = page_soup.find_all("ul", class_="pagination")
    max_pages = int(ul_tag[0].find_all("a")[-2].text)
    try:

        current_page = 1
        while current_page <= max_pages:
            # Construct the URL for the current page
            current_url = f"{url}?page_num={current_page}" if current_page > 1 else url

            # Send a GET request to the URL
            request = Request(current_url, headers={'User-Agent': 'Mozilla/5.0'})
            uClient = urlopen(request)

            # Parse HTML content
            page_soup = soup(uClient.read(), "html.parser")
            uClient.close()

            # Extract relevant data elements
            teams = page_soup.find_all("tr", class_=class_name)
            all_teams.extend(teams)

            # Move to the next page
            current_page += 1

    except Exception as e:
        print(f"Failed to retrieve data. Error: {e}")

    return all_teams

def data_to_csv():
  teams = []
  for team in extracted_teams:
    team = team.text.split("\n\n")
    for i in range(0, len(team)):
      team[i] = team[i].strip()
    team.pop(5)
    team.pop(0)
    teams.append(team)
  df = pd.DataFrame(teams, columns=['name', 'year', 'wins', 'losses', 'pct_text_success', 'gf', 'ga', 'diff_text_success'])
  return df.to_csv("teams.csv")